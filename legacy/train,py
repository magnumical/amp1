import os
import logging
import gc
from joblib import Parallel, delayed
import mlflow
import mlflow.keras
import numpy as np
import pandas as pd
import librosa
import librosa.display
import optuna
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.utils import to_categorical, normalize
from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D

from imblearn.over_sampling import RandomOverSampler
from keras.preprocessing.image import ImageDataGenerator
from imblearn.over_sampling import SMOTE


from keras.models import Sequential
from keras.layers import (
    Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,
    GlobalAveragePooling1D, GlobalAveragePooling2D,
    Dense, Dropout, BatchNormalization
)


from tensorflow.keras.models import Sequential, Model, load_model

from tensorflow.keras.layers import Conv1D, Conv2D, SeparableConv1D, MaxPooling1D, MaxPooling2D
from tensorflow.keras.layers import Input, add, Flatten, Dense, BatchNormalization, Dropout, LSTM, GRU
from tensorflow.keras.layers import GlobalMaxPooling1D, GlobalMaxPooling2D, Activation, LeakyReLU, ReLU

from tensorflow.keras import regularizers
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef
from sklearn.metrics import cohen_kappa_score,roc_auc_score,confusion_matrix,classification_report


# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
data_logger = logging.getLogger("data_loading")
processing_logger = logging.getLogger("data_processing")
model_logger = logging.getLogger("model_training")

# Utility Functions
def load_data():
    """Load patient diagnosis and demographic data."""
    data_logger.info("Loading patient diagnosis and demographic data.")
    diagnosis_df = pd.read_csv('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv', 
                               names=['Patient number', 'Diagnosis'])

    patient_df = pd.read_csv('/kaggle/input/respiratory-sound-database/demographic_info.txt', 
                             names=['Patient number', 'Age', 'Sex', 'Adult BMI (kg/m2)', 'Child Weight (kg)', 'Child Height (cm)'],
                             delimiter=' ')

    data_logger.info("Data successfully loaded.")
    return pd.merge(left=patient_df, right=diagnosis_df, how='left')


def process_audio_file(soundDir, audio_files_path, df_filtered):
    """
    Process a single audio file: extract MFCC features and augment with noise, stretching, and shifting.
    
    Args:
        soundDir: Filename of the audio file.
        audio_files_path: Path to the directory containing audio files.
        df_filtered: Filtered DataFrame containing patient diagnosis and metadata.
        
    Returns:
        Tuple containing features (X_local) and labels (y_local).
    """
    X_local = []
    y_local = []
    features = 52

    # Extract patient ID and disease from filename and DataFrame
    patient_id = int(soundDir.split('_')[0])
    disease = df_filtered.loc[df_filtered['Patient number'] == patient_id, 'Diagnosis'].values[0]

    # Load audio file
    data_x, sampling_rate = librosa.load(os.path.join(audio_files_path, soundDir), sr=None)
    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T, axis=0)
    X_local.append(mfccs)
    y_local.append(disease)

    # Data augmentation
    for augmentation in [add_noise, shift, stretch, pitch_shift]:
        if augmentation == add_noise:
            augmented_data = augmentation(data_x, 0.001)
        elif augmentation == shift:
            augmented_data = augmentation(data_x, 1600)
        elif augmentation == stretch:
            augmented_data = augmentation(data_x, 1.2)
        elif augmentation == pitch_shift:
            augmented_data = augmentation(data_x, 3)

        mfccs_augmented = np.mean(librosa.feature.mfcc(y=augmented_data, sr=sampling_rate, n_mfcc=features).T, axis=0)
        X_local.append(mfccs_augmented)
        y_local.append(disease)

    return X_local, y_local



def mfccs_feature_exteraction(audio_files_path, df_filtered, n_jobs=-1):
    """
    Extract MFCC features from audio data and augment with noise, stretching, and shifting in parallel.
    
    Args:
        audio_files_path: Path to the directory containing audio files.
        df_filtered: Filtered DataFrame containing patient diagnosis and metadata.
        n_jobs: Number of parallel jobs (-1 to use all available cores).

    Returns:
        X_data: Array of features extracted from the audio files.
        y_data: Array of target labels.
    """
    processing_logger.info(f"Processing audio files in: {audio_files_path}")
    files = [file for file in os.listdir(audio_files_path) if file.endswith('.wav') and file[:3] not in ['103', '108', '115']]
   
    files = files[:30] ## DEBUG

    # Use Parallel and delayed to process files in parallel
    results = Parallel(n_jobs=n_jobs, backend="loky")(delayed(process_audio_file)(file, audio_files_path, df_filtered) for file in tqdm(files, desc="Processing audio files"))

    # Flatten results
    X_ = []
    y_ = []
    for X_local, y_local in results:
        X_.extend(X_local)
        y_.extend(y_local)

    X_data = np.array(X_)
    y_data = np.array(y_)
    processing_logger.info("MFCC feature extraction and augmentation complete.")
    return X_data, y_data



def add_noise(data,x):
    noise = np.random.randn(len(data))
    data_noise = data + x * noise
    return data_noise

def shift(data, x):
    return np.roll(data, int(x))

def stretch(data, rate):
    """Apply time-stretching to the audio signal."""
    return librosa.effects.time_stretch(data, rate=rate)



def pitch_shift (data , rate):
    data = librosa.effects.pitch_shift(data, sr=220250, n_steps=rate)
    return data

def prepare_dataset_augmented(df_filtered, audio_files_path):
    """Prepare the dataset using the GRU pipeline."""
    processing_logger.info("Preparing dataset with GRU pipeline.")
    
    # Extract features and labels
    X, y = mfccs_feature_exteraction(audio_files_path, df_filtered)
    
    # Apply label encoding
    le = LabelEncoder()
    y_encoded = le.fit_transform(np.array(y))  # Encode labels to integers
    y_one_hot = to_categorical(y_encoded)      # Convert to one-hot encoding
    
    # Log the mapping of one-hot encoding to class labels
    print("One-hot encoding mapping:")
    for idx, label in enumerate(le.classes_):
        print(f"{idx} -> {label}")
    
    processing_logger.info("Dataset preparation with GRU pipeline complete.")
    return X, y_one_hot, le



def process_audio_metadata(folder_path):
    """Extract audio metadata from filenames."""
    processing_logger.info("Extracting audio metadata from filenames.")
    data = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.txt'):
            parts = filename.split('_')
            data.append({
                'Patient number': int(parts[0]),
                'Recording index': parts[1],
                'Chest location': parts[2],
                'Acquisition mode': parts[3],
                'Recording equipment': parts[4].split('.')[0]
            })
    processing_logger.info("Audio metadata extraction complete.")
    return pd.DataFrame(data)

def merge_datasets(df1, df2):
    """Merge metadata and diagnosis data."""
    processing_logger.info("Merging metadata and diagnosis data.")
    merged_df = pd.merge(left=df1, right=df2, how='left').sort_values('Patient number').reset_index(drop=True)
    merged_df['audio_file_name'] = merged_df.apply(lambda row: f"{row['Patient number']}_{row['Recording index']}_{row['Chest location']}_{row['Acquisition mode']}_{row['Recording equipment']}.wav", axis=1)
    processing_logger.info("Merging complete.")
    return merged_df

def filter_and_sample_data(df, mode='binary'):
    """
    Filter and sample the dataset for binary or multi-class classification.

    Args:
        df: Input DataFrame containing diagnosis data.
        mode: Specify 'binary' for Normal/Abnormal or 'multi-class' for grouped classes.

    Returns:
        Filtered and processed DataFrame.
    """
    processing_logger.info(f"Filtering and sampling the dataset for {mode} classification.")
    
    if mode == 'binary':
        # Binary classification: Normal vs. Abnormal
        df['Diagnosis'] = df['Diagnosis'].apply(lambda x: 'Normal' if x == 'Healthy' else 'Abnormal')
    elif mode == 'multi':
        # Multi-class classification: Group classes
        processing_logger.info("Grouping classes for multi-class classification.")
        df['Diagnosis'] = df['Diagnosis'].replace({
            'Healthy': 'Normal',
            'COPD': 'Chronic Respiratory Diseases',
            'Asthma': 'Chronic Respiratory Diseases',
            'URTI': 'Respiratory Infections',
            'Bronchiolitis': 'Respiratory Infections',
            'LRTI': 'Respiratory Infections',
            'Pneumonia': 'Respiratory Infections',
            'Bronchiectasis': 'Respiratory Infections'
        })

    # Filter out rare classes with fewer than 5 samples
    class_counts = df['Diagnosis'].value_counts()
    valid_classes = class_counts[class_counts >= 5].index
    df = df[df['Diagnosis'].isin(valid_classes)].reset_index(drop=True)

    processing_logger.info(f"Filtered classes: {df['Diagnosis'].unique()}")
    processing_logger.info(f"Filtering and sampling complete with mode={mode}.")
    return df


def oversample_data(X, y):
    """Apply SMOTE to balance classes."""
    processing_logger.info("Applying SMOTE to balance classes.")
    
    # Save the original shape of features
    original_shape = X.shape[1:]  
    
    # Flatten for SMOTE processing
    X = X.reshape((X.shape[0], -1))
    
    # Convert one-hot encoded labels to integers
    y = np.argmax(y, axis=1)
    
    # Apply SMOTE
    smote = SMOTE(random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X, y)
    
    # Reshape back to the original dimensions
    X_resampled = X_resampled.reshape((-1, *original_shape))
    
    # Convert labels back to one-hot encoding
    y_resampled = to_categorical(y_resampled)
    
    processing_logger.info("SMOTE oversampling complete.")
    return X_resampled, y_resampled



def augment_data(X, y):
    """Apply data augmentation to increase dataset size."""
    processing_logger.info("Applying data augmentation.")
    datagen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.1,
        height_shift_range=0.1,
        horizontal_flip=True
    )
    datagen.fit(X)
    processing_logger.info("Data augmentation setup complete.")
    return datagen



def prepare_dataset_parallel(df, audio_files_path, mode):
    """Prepare the dataset by extracting features from audio files in parallel."""
    processing_logger.info(f"Preparing dataset using {mode} features in parallel.")
    results = Parallel(n_jobs=-1)(delayed(preprocess_file)(row, audio_files_path, mode) for _, row in tqdm(df.iterrows(), total=len(df)))

    X, y = zip(*results)
    X = np.array(X)
    X = np.expand_dims(X, axis=-1)  # Add channel dimension
    X = normalize(X, axis=1)
    le = LabelEncoder()
    y = to_categorical(le.fit_transform(np.array(y)))

    processing_logger.info(f"Dataset preparation using {mode} complete.")
    return X, y, le

def preprocess_file(row, audio_files_path, mode):
    """Preprocess a single audio file."""
    file_path = os.path.join(audio_files_path, row['audio_file_name'])
    feature = preprocessing(file_path, mode)
    label = row['Diagnosis']
    return feature, label
    
def preprocessing(audio_file, mode):
    """Preprocess audio file by resampling, padding/truncating, and extracting features."""
    sr_new = 16000  # Resample audio to 16 kHz
    x, sr = librosa.load(audio_file, sr=sr_new)

    # Padding or truncating to 5 seconds (5 * sr_new samples)
    max_len = 5 * sr_new
    if x.shape[0] < max_len:
        x = np.pad(x, (0, max_len - x.shape[0]))
    else:
        x = x[:max_len]

    # Extract features
    if mode == 'mfcc':
        feature = librosa.feature.mfcc(y=x, sr=sr_new, n_mfcc=20)  # Ensure consistent shape
    elif mode == 'log_mel':
        feature = librosa.feature.melspectrogram(y=x, sr=sr_new, n_mels=20, fmax=8000)  # Match n_mels to 20
        feature = librosa.power_to_db(feature, ref=np.max)

    return feature

def prepare_dataset(df, audio_files_path, mode):
    """Prepare the dataset by extracting features from audio files."""
    processing_logger.info(f"Preparing dataset using {mode} features.")
    X, y = [], []
    for _, row in tqdm(df.iterrows(), total=len(df)):
        file_path = os.path.join(audio_files_path, row['audio_file_name'])
        feature = preprocessing(file_path, mode)
        X.append(feature)
        y.append(row['Diagnosis'])
        del feature  # Free memory after processing each file
        gc.collect()

    X = np.array(X)
    X = np.expand_dims(X, axis=-1)  # Add channel dimension
    X = normalize(X, axis=1)
    le = LabelEncoder()
    y = to_categorical(le.fit_transform(np.array(y)))
    processing_logger.info(f"Dataset preparation using {mode} complete.")
    return X, y, le



def build_model(input_shape, n_filters, dense_units, dropout_rate, num_classes, model_type='1D'):
    """
    Build and compile a CNN model for 1D or 2D data.

    Args:
        input_shape: Tuple specifying the input shape.
        n_filters: Number of filters in the first convolutional layer.
        dense_units: Number of units in the dense layer.
        dropout_rate: Dropout rate for regularization.
        num_classes: Number of output classes.
        model_type: '1D' for 1D CNN or '2D' for 2D CNN.

    Returns:
        Compiled CNN model.
    """
    print(f"Building the updated {model_type} CNN model.")
    model = Sequential()

    if model_type == '1D':
        # 1D CNN layers
        model.add(Conv1D(n_filters, kernel_size=3, activation='relu', input_shape=input_shape))
        model.add(BatchNormalization())
        model.add(MaxPooling1D(pool_size=2))
        model.add(Dropout(dropout_rate))

        model.add(Conv1D(n_filters * 2, kernel_size=3, activation='relu'))
        model.add(BatchNormalization())
        model.add(MaxPooling1D(pool_size=2))
        model.add(Dropout(dropout_rate))

        model.add(Conv1D(n_filters * 4, kernel_size=3, activation='relu'))
        model.add(BatchNormalization())
        model.add(GlobalAveragePooling1D())
        model.add(Dropout(dropout_rate))

    elif model_type == '2D':
        # 2D CNN layers
        model.add(Conv2D(n_filters, (3, 3), activation='relu', input_shape=input_shape))
        model.add(BatchNormalization())
        if input_shape[0] >= 2:
            model.add(MaxPooling2D((2, 2)))
        model.add(Dropout(dropout_rate))

        model.add(Conv2D(n_filters * 2, (3, 3), activation='relu'))
        model.add(BatchNormalization())
        if input_shape[0] >= 4:
            model.add(MaxPooling2D((2, 2)))
        model.add(Dropout(dropout_rate))

        model.add(Conv2D(n_filters * 4, (3, 3), activation='relu'))
        model.add(BatchNormalization())
        model.add(GlobalAveragePooling2D())
        model.add(Dropout(dropout_rate))

    else:
        raise ValueError("Invalid model_type. Must be '1D' or '2D'.")

    # Fully connected layers
    model.add(Dense(dense_units, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(dropout_rate))
    model.add(Dense(num_classes, activation='sigmoid' if num_classes == 1 else 'softmax'))

    # Compile the model
    loss = 'binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy'
    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])
    print(f"{model_type} CNN model built and compiled successfully.")
    return model



def log_metrics(y_true, y_pred, mode):
    """Log evaluation metrics."""
    precision = classification_report(y_true, y_pred, output_dict=True)['weighted avg']['precision']
    recall = classification_report(y_true, y_pred, output_dict=True)['weighted avg']['recall']
    f1_score = classification_report(y_true, y_pred, output_dict=True)['weighted avg']['f1-score']

    mlflow.log_metric(f"{mode}_precision", precision)
    mlflow.log_metric(f"{mode}_recall", recall)
    mlflow.log_metric(f"{mode}_f1_score", f1_score)

def evaluate_model(model, X_test, y_test, le, mode):
    """Evaluate the model and display results."""
    model_logger.info(f"Evaluating the model using {mode} features.")
    predictions = model.predict(X_test)
    predicted_classes = np.argmax(predictions, axis=1)
    y_true = np.argmax(y_test, axis=1)

    # Confusion Matrix
    conf_matrix = confusion_matrix(y_true, predicted_classes)
    plt.figure(figsize=(8, 6))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f"Confusion Matrix ({mode})")
    plt.colorbar()
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    cm_path = f"confusion_matrix_{mode}.png"
    plt.savefig(cm_path)
    mlflow.log_artifact(cm_path)

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_true, predictions[:, 1])
    auc_score = roc_auc_score(y_true, predictions[:, 1])
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f"ROC curve (area = {auc_score:.2f})")
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f"Receiver Operating Characteristic ({mode})")
    plt.legend(loc="lower right")
    roc_path = f"roc_curve_{mode}.png"
    plt.savefig(roc_path)
    mlflow.log_artifact(roc_path)

    # Log metrics
    mlflow.log_metric(f"{mode}_auc", auc_score)
    log_metrics(y_true, predicted_classes, mode)

    model_logger.info(f"Model evaluation using {mode} features complete.")


def track_experiment_with_mlflow_and_optuna(mode, num_classes, model_type='1D'):
    """
    Optimize hyperparameters using Optuna and track experiments with MLflow.

    Args:
        mode: Feature extraction mode (e.g., 'gru', 'mfcc', 'log_mel').
        num_classes: Number of classes for classification.
        model_type: Type of model ('1D' for Conv1D, '2D' for Conv2D).
    """
    def objective(trial):
        with mlflow.start_run(nested=True):  # Start a new MLflow run for each trial
            # Hyperparameters to tune
            n_filters = trial.suggest_categorical('n_filters', [16, 32, 64])
            dense_units = trial.suggest_int('dense_units', 64, 256, step=32)
            dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5, step=0.1)
            learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)

            # Build and compile the model
            model = build_model(
                input_shape=X_train.shape[1:], 
                n_filters=n_filters, 
                dense_units=dense_units, 
                dropout_rate=dropout_rate,
                num_classes=num_classes,
                model_type=model_type  # Pass model type to build_model
            )
            model.compile(
                optimizer=Adamax(learning_rate=learning_rate),
                loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy',
                metrics=['accuracy']
            )

            # Train the model
            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), 
                                epochs=10, batch_size=32, verbose=0)

            # Log hyperparameters and metrics to MLflow
            mlflow.log_params({
                'n_filters': n_filters,
                'dense_units': dense_units,
                'dropout_rate': dropout_rate,
                'learning_rate': learning_rate,
                'model_type': model_type
            })
            mlflow.log_metric("best_val_accuracy", max(history.history['val_accuracy']))

            # Save training and validation loss curves
            plt.figure()
            plt.plot(history.history['loss'], label='Train Loss')
            plt.plot(history.history['val_loss'], label='Validation Loss')
            plt.legend()
            plt.title("Training and Validation Loss")
            loss_curve_path = f"loss_curve_{trial.number}_{model_type}.png"
            plt.savefig(loss_curve_path)
            mlflow.log_artifact(loss_curve_path)

            return max(history.history['val_accuracy'])

    # Start Optuna study
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=20)

    # Retrieve best trial and log results
    best_trial = study.best_trial
    model_logger.info(f"Best Trial for {mode} ({model_type}): {best_trial.params}")

    # Build and train the best model
    best_model = build_model(
        input_shape=X_train.shape[1:], 
        n_filters=best_trial.params['n_filters'], 
        dense_units=best_trial.params['dense_units'], 
        dropout_rate=best_trial.params['dropout_rate'], 
        num_classes=num_classes,
        model_type=model_type
    )
    best_model.compile(
        optimizer=Adamax(learning_rate=best_trial.params['learning_rate']),
        loss='binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy',
        metrics=['accuracy']
    )
    best_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, verbose=1)

    # Save the best model
    best_model_path = f"best_model_{mode}_{model_type}.h5"
    best_model.save(best_model_path)
    mlflow.log_artifact(best_model_path)
    model_logger.info(f"Best model for {mode} ({model_type}) saved successfully.")

    return best_model



def log_class_distribution(y, message):
    """Log the class distribution."""
    unique, counts = np.unique(np.argmax(y, axis=1), return_counts=True)
    class_distribution = dict(zip(unique, counts))
    processing_logger.info(f"{message} Class Distribution: {class_distribution}")

def main():
    mlflow.end_run() 
    
    data_logger.info("Starting data pipeline.")
    df = load_data()
    audio_metadata = process_audio_metadata('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files')
    df_all = merge_datasets(audio_metadata, df)

    # Define classification modes and feature types
    classification_modes = ['binary', 'multi']  # Options: 'binary', 'multi'
    feature_types = ['augmented', 'mfcc', 'log_mel']  # Options: 
    models = []

    for classification_mode in classification_modes:
        # Preprocess dataset for binary or multi-class classification
        df_filtered = filter_and_sample_data(df_all, mode=classification_mode)
        processing_logger.info(f"Dataset shape for {classification_mode} mode: {df_filtered.shape}")
        
        for feature_type in feature_types:
            processing_logger.info(f"Running experiment for {classification_mode} classification with {feature_type} features.")
            global X_train, X_val, X_test, y_train, y_val, y_test

            # Prepare the dataset
            if feature_type == 'augmented':
                X, y, le = prepare_dataset_augmented(df_filtered, '/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files')
            else:
                X, y, le = prepare_dataset_parallel(df_filtered, '/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files', mode=feature_type)

            # Split data into train/val/test
            X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
            X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)

            # Save test data for future evaluation
            np.save(f"X_test_{classification_mode}_{feature_type}.npy", X_test)
            np.save(f"y_test_{classification_mode}_{feature_type}.npy", y_test)
            mlflow.log_artifact(f"X_test_{classification_mode}_{feature_type}.npy")
            mlflow.log_artifact(f"y_test_{classification_mode}_{feature_type}.npy")

            # Log dataset characteristics
            log_class_distribution(y_train, "Before Oversampling")
            processing_logger.info(f"Train size: {X_train.shape}, Validation size: {X_val.shape}, Test size: {X_test.shape}")

            try:
                X_train, y_train = oversample_data(X_train, y_train)
            except ValueError as e:
                processing_logger.warning(f"SMOTE skipped: {e}")
            log_class_distribution(y_train, "After Oversampling")

            # Train and save model
            with mlflow.start_run(run_name=f"Experiment_{classification_mode}_{feature_type}", nested=True):
                if feature_type == 'augmented':
                    # Expand dimensions for 1D CNN input
                    X_train = np.expand_dims(X_train, axis=-1)
                    X_val = np.expand_dims(X_val, axis=-1)
                    X_test = np.expand_dims(X_test, axis=-1)

                    # Optimize and train 1D CNN
                    model = track_experiment_with_mlflow_and_optuna(
                        mode=feature_type,
                        num_classes=y_train.shape[1],
                        model_type='1D'  # Specify 1D CNN for GRU features
                    )
                else:
                    # Optimize and train CNN models for MFCC and MEL
                    model = track_experiment_with_mlflow_and_optuna(
                        mode=feature_type,
                        num_classes=y_train.shape[1],
                        model_type='2D'  # Specify 2D CNN for MFCC and Log-Mel
                    )

                # Log evaluation metrics
                evaluate_model(model, X_test, y_test, le, mode=feature_type)

                # Save final model
                final_model_path = f"final_model_{classification_mode}_{feature_type}.h5"
                model.save(final_model_path)
                mlflow.log_artifact(final_model_path)
                models.append(model)

    processing_logger.info("All experiments completed successfully!")

if __name__ == "__main__":
    main()

